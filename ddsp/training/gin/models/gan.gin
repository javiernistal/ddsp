# -*-Python-*-
# Autoencoder that decodes from (loudness, f0, z).
# z = encoder(audio)

import ddsp
import ddsp.training

# =====
# Model
# =====
get_model.model = @models.GAN()

# Preprocessor
GAN.preprocessor = @preprocessing.DefaultPreprocessor()
DefaultPreprocessor.time_steps = 1000

# Discriminator
GAN.discriminator = @encoders.MfccTimeDistributedRnnEncoder()
MfccTimeDistributedRnnEncoder.rnn_channels = 512
MfccTimeDistributedRnnEncoder.rnn_type = 'gru'
MfccTimeDistributedRnnEncoder.z_dims = 16
MfccTimeDistributedRnnEncoder.z_time_steps = 125

# Generator
GAN.generator = @gan_modules.Generator()
Generator.ch = 512
Generator.output_splits = (('amps', 1),
                               ('harmonic_distribution', 100),
                               ('noise_magnitudes', 65))

# Losses
GAN.losses = [
    @losses.GANLoss(),
]


# ==============
# ProcessorGroup
# ==============

GAN.processor_group = @processors.ProcessorGroup()

ProcessorGroup.dag = [
  (@synths.Additive(),
    ['amps', 'harmonic_distribution', 'f0_hz']),
  (@synths.FilteredNoise(),
    ['noise_magnitudes']),
  (@processors.Add(),
    ['filtered_noise/signal', 'additive/signal']),
]

# Additive Synthesizer
Additive.name = 'additive'
Additive.n_samples = 64000
Additive.sample_rate = 16000
Additive.normalize_below_nyquist = True
Additive.scale_fn = @core.exp_sigmoid

# Filtered Noise Synthesizer
FilteredNoise.name = 'filtered_noise'
FilteredNoise.n_samples = 64000
FilteredNoise.window_size = 0
FilteredNoise.scale_fn = @core.exp_sigmoid

# Add
Add.name = 'add'



# Encoder (with F0 encoder)
MfccTimeDistributedRnnEncoder.z_time_steps = 250
MfccTimeDistributedRnnEncoder.f0_encoder = @encoders.ResnetF0Encoder()
ResnetF0Encoder.size = 'small'
ResnetF0Encoder.f0_bins = 256

# FFT input parameters from onsets and frames transcription experiments.
ResnetF0Encoder.spectral_fn = @f0_spectral/spectral_ops.compute_logmel
f0_spectral/compute_logmel.lo_hz = 0.0
f0_spectral/compute_logmel.hi_hz = 8000.0
f0_spectral/compute_logmel.bins = 229
f0_spectral/compute_logmel.fft_size = 2048
f0_spectral/compute_logmel.overlap = 0.75
f0_spectral/compute_logmel.pad_end = True


# Crepe
PretrainedCREPEEmbeddingLoss.name = 'crepe'
PretrainedCREPEEmbeddingLoss.loss_type = 'L1'
PretrainedCREPEEmbeddingLoss.weight = 0.1
PretrainedCREPEEmbeddingLoss.activation_layer = 'conv5-maxpool'
PretrainedCREPEEmbeddingLoss.model_capacity = 'tiny'
